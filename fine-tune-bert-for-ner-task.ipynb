{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\n\nraw_datasets = load_dataset(\"conll2003\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-23T12:43:14.623178Z","iopub.execute_input":"2025-06-23T12:43:14.623880Z","iopub.status.idle":"2025-06-23T12:43:15.389221Z","shell.execute_reply.started":"2025-06-23T12:43:14.623858Z","shell.execute_reply":"2025-06-23T12:43:15.388514Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"raw_datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T12:43:17.713338Z","iopub.execute_input":"2025-06-23T12:43:17.713668Z","iopub.status.idle":"2025-06-23T12:43:17.718620Z","shell.execute_reply.started":"2025-06-23T12:43:17.713646Z","shell.execute_reply":"2025-06-23T12:43:17.717812Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 14041\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3250\n    })\n    test: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3453\n    })\n})"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"# inputs are in form in list of tokens not sentences","metadata":{}},{"cell_type":"code","source":"raw_datasets[\"train\"][0][\"tokens\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T12:43:21.395949Z","iopub.execute_input":"2025-06-23T12:43:21.396565Z","iopub.status.idle":"2025-06-23T12:43:21.401683Z","shell.execute_reply.started":"2025-06-23T12:43:21.396540Z","shell.execute_reply":"2025-06-23T12:43:21.400925Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"ner_feature = raw_datasets[\"train\"].features[\"ner_tags\"]\nner_feature","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T12:43:22.112841Z","iopub.execute_input":"2025-06-23T12:43:22.113083Z","iopub.status.idle":"2025-06-23T12:43:22.118306Z","shell.execute_reply.started":"2025-06-23T12:43:22.113066Z","shell.execute_reply":"2025-06-23T12:43:22.117638Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"O means the word doesnâ€™t correspond to any entity.\n\nB-PER/I-PER means the word corresponds to the beginning of/is inside a person entity.\n\nB-ORG/I-ORG means the word corresponds to the beginning of/is inside an organization entity.\n\nB-LOC/I-LOC means the word corresponds to the beginning of/is inside a location entity.\n\nB-MISC/I-MISC means the word corresponds to the beginning of/is inside a miscellaneous entity","metadata":{}},{"cell_type":"code","source":"label_names=ner_feature.feature.names\nlabel_names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T13:07:13.732254Z","iopub.execute_input":"2025-06-23T13:07:13.732844Z","iopub.status.idle":"2025-06-23T13:07:13.737341Z","shell.execute_reply.started":"2025-06-23T13:07:13.732821Z","shell.execute_reply":"2025-06-23T13:07:13.736670Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"},"metadata":{}}],"execution_count":30},{"cell_type":"markdown","source":"# Tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_checkpoint = \"bert-base-cased\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T12:48:08.970722Z","iopub.execute_input":"2025-06-23T12:48:08.971398Z","iopub.status.idle":"2025-06-23T12:48:22.761629Z","shell.execute_reply.started":"2025-06-23T12:48:08.971374Z","shell.execute_reply":"2025-06-23T12:48:22.760883Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f29afa5ce59d49d9b2f854eb4c5359dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ec66c78ad584700a334e87290e1a77b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5de48fdfbf744a23a65e3566b1881028"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"260dd972090a4b6b9939a885b7afd2a3"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"inputs = tokenizer(raw_datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)\ninputs.tokens()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T12:48:57.518569Z","iopub.execute_input":"2025-06-23T12:48:57.519061Z","iopub.status.idle":"2025-06-23T12:48:57.527983Z","shell.execute_reply.started":"2025-06-23T12:48:57.519039Z","shell.execute_reply":"2025-06-23T12:48:57.527265Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"['[CLS]',\n 'EU',\n 'rejects',\n 'German',\n 'call',\n 'to',\n 'boycott',\n 'British',\n 'la',\n '##mb',\n '.',\n '[SEP]']"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"# As we saw that the tokenizer split lamp into subwords so this will affect the labels so we will assign the new tokens to -100 which will be ignored by cross entropy \n\n# For tokens inside a word but not at the beginning, we replace the B- with I- (since the token does not begin the entity)","metadata":{}},{"cell_type":"code","source":"def align_labels_with_tokens(labels, word_ids):\n    new_labels = []\n    current_word = None\n    for word_id in word_ids:\n        if word_id != current_word:\n            # Start of a new word!\n            current_word = word_id\n            label = -100 if word_id is None else labels[word_id]\n            new_labels.append(label)\n        elif word_id is None:\n            # Special token\n            new_labels.append(-100)\n        else:\n            # Same word as previous token\n            label = labels[word_id]\n            # If the label is B-XXX we change it to I-XXX\n            if label % 2 == 1:\n                label += 1\n            new_labels.append(label)\n\n    return new_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T12:54:54.774382Z","iopub.execute_input":"2025-06-23T12:54:54.775101Z","iopub.status.idle":"2025-06-23T12:54:54.780838Z","shell.execute_reply.started":"2025-06-23T12:54:54.775075Z","shell.execute_reply":"2025-06-23T12:54:54.780202Z"}},"outputs":[{"name":"stdout","text":"The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"labels = raw_datasets[\"train\"][0][\"ner_tags\"]\nword_ids = inputs.word_ids()\nprint(labels)\nprint(align_labels_with_tokens(labels, word_ids))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T12:55:10.490990Z","iopub.execute_input":"2025-06-23T12:55:10.491275Z","iopub.status.idle":"2025-06-23T12:55:10.496149Z","shell.execute_reply.started":"2025-06-23T12:55:10.491255Z","shell.execute_reply":"2025-06-23T12:55:10.495551Z"}},"outputs":[{"name":"stdout","text":"[3, 0, 7, 0, 0, 0, 7, 0, 0]\n[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"as we can see that gaves -100 for the two special tokens at the beginning(CLS) and the end(SEP), and a new 0 for our word that was split into two tokens.","metadata":{}},{"cell_type":"markdown","source":"# Apply this to the whole dataset","metadata":{}},{"cell_type":"code","source":"def tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(\n        examples[\"tokens\"], truncation=True, is_split_into_words=True\n    )\n    all_labels = examples[\"ner_tags\"]\n    new_labels = []\n    for i, labels in enumerate(all_labels):\n        word_ids = tokenized_inputs.word_ids(i)\n        new_labels.append(align_labels_with_tokens(labels, word_ids))\n\n    tokenized_inputs[\"labels\"] = new_labels\n    return tokenized_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T12:58:27.055880Z","iopub.execute_input":"2025-06-23T12:58:27.056618Z","iopub.status.idle":"2025-06-23T12:58:27.060635Z","shell.execute_reply.started":"2025-06-23T12:58:27.056595Z","shell.execute_reply":"2025-06-23T12:58:27.060062Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"tokenized_datasets = raw_datasets.map(\n    tokenize_and_align_labels,\n    batched=True,\n    remove_columns=raw_datasets[\"train\"].column_names,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T12:58:58.590081Z","iopub.execute_input":"2025-06-23T12:58:58.590737Z","iopub.status.idle":"2025-06-23T12:59:00.750620Z","shell.execute_reply.started":"2025-06-23T12:58:58.590706Z","shell.execute_reply":"2025-06-23T12:59:00.749905Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14041 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8eb14baa4b54d2aae7797af464359ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83ad2657b73d4a339302c8d1d8bb7254"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0c011ce0a0d43628d355c0814ab6253"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"tokenized_datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T13:00:14.982496Z","iopub.execute_input":"2025-06-23T13:00:14.982769Z","iopub.status.idle":"2025-06-23T13:00:14.987117Z","shell.execute_reply.started":"2025-06-23T13:00:14.982749Z","shell.execute_reply":"2025-06-23T13:00:14.986475Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n        num_rows: 14041\n    })\n    validation: Dataset({\n        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n        num_rows: 3250\n    })\n    test: Dataset({\n        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n        num_rows: 3453\n    })\n})"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"print(tokenized_datasets['train']['token_type_ids'][10])\nprint(tokenized_datasets['train']['labels'][10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T13:02:03.302257Z","iopub.execute_input":"2025-06-23T13:02:03.302560Z","iopub.status.idle":"2025-06-23T13:02:03.584796Z","shell.execute_reply.started":"2025-06-23T13:02:03.302539Z","shell.execute_reply":"2025-06-23T13:02:03.583962Z"}},"outputs":[{"name":"stdout","text":"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n[-100, 7, 0, 0, 1, 2, 2, 2, 2, 0, 0, 0, 1, 2, 2, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"id2label = {i: label for i, label in enumerate(label_names)}\nlabel2id = {v: k for k, v in id2label.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T13:13:10.561958Z","iopub.execute_input":"2025-06-23T13:13:10.563266Z","iopub.status.idle":"2025-06-23T13:13:10.566899Z","shell.execute_reply.started":"2025-06-23T13:13:10.563240Z","shell.execute_reply":"2025-06-23T13:13:10.566161Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"from transformers import AutoModelForTokenClassification\n\nmodel = AutoModelForTokenClassification.from_pretrained(\n    model_checkpoint,\n    id2label=id2label,\n    label2id=label2id,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T13:13:42.596832Z","iopub.execute_input":"2025-06-23T13:13:42.597530Z","iopub.status.idle":"2025-06-23T13:13:45.202257Z","shell.execute_reply.started":"2025-06-23T13:13:42.597508Z","shell.execute_reply":"2025-06-23T13:13:45.201736Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da18baf2c3db4b50b60c6bfa59194acd"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"from transformers import TrainingArguments\n\nargs = TrainingArguments(\n    \"bert-finetuned-ner\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    num_train_epochs=3,\n    weight_decay=0.01,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T13:25:46.698305Z","iopub.execute_input":"2025-06-23T13:25:46.698612Z","iopub.status.idle":"2025-06-23T13:25:46.731038Z","shell.execute_reply.started":"2025-06-23T13:25:46.698591Z","shell.execute_reply":"2025-06-23T13:25:46.730437Z"}},"outputs":[],"execution_count":46},{"cell_type":"markdown","source":"# We want to make a dynamic padding of our inputs and labels so we will use data_collatorsed which dynamically pad inputs and labels to the same length within a batch during training","metadata":{}},{"cell_type":"code","source":"from transformers import DataCollatorForTokenClassification\n\ndata_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T13:25:18.343970Z","iopub.execute_input":"2025-06-23T13:25:18.344287Z","iopub.status.idle":"2025-06-23T13:25:18.348170Z","shell.execute_reply.started":"2025-06-23T13:25:18.344267Z","shell.execute_reply":"2025-06-23T13:25:18.347336Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# # !pip install seqeval\n# !pip install evaluate","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"seqeval\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T13:49:09.687896Z","iopub.execute_input":"2025-06-23T13:49:09.688198Z","iopub.status.idle":"2025-06-23T13:49:10.179444Z","shell.execute_reply.started":"2025-06-23T13:49:09.688178Z","shell.execute_reply":"2025-06-23T13:49:10.178860Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cd36216e67a44ab983ed4d1d5440826"}},"metadata":{}}],"execution_count":60},{"cell_type":"code","source":"import numpy as np\n\n\ndef compute_metrics(eval_preds):\n    logits, labels = eval_preds\n    predictions = np.argmax(logits, axis=-1)\n\n    # Remove ignored index (special tokens) and convert to labels\n    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n    true_predictions = [\n        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n    return {\n        \"precision\": all_metrics[\"overall_precision\"],\n        \"recall\": all_metrics[\"overall_recall\"],\n        \"f1\": all_metrics[\"overall_f1\"],\n        \"accuracy\": all_metrics[\"overall_accuracy\"],\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T13:25:19.241249Z","iopub.execute_input":"2025-06-23T13:25:19.241967Z","iopub.status.idle":"2025-06-23T13:25:19.246595Z","shell.execute_reply.started":"2025-06-23T13:25:19.241944Z","shell.execute_reply":"2025-06-23T13:25:19.245927Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    processing_class=tokenizer,\n)\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T13:47:40.830183Z","iopub.status.idle":"2025-06-23T13:47:40.830501Z","shell.execute_reply.started":"2025-06-23T13:47:40.830316Z","shell.execute_reply":"2025-06-23T13:47:40.830332Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Using accelrate to fast the training process","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_dataloader = DataLoader(\n    tokenized_datasets[\"train\"],\n    shuffle=True,\n    collate_fn=data_collator,\n    batch_size=8,\n)\neval_dataloader = DataLoader(\n    tokenized_datasets[\"validation\"], collate_fn=data_collator, batch_size=8\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T13:42:36.471130Z","iopub.execute_input":"2025-06-23T13:42:36.471890Z","iopub.status.idle":"2025-06-23T13:42:36.475808Z","shell.execute_reply.started":"2025-06-23T13:42:36.471868Z","shell.execute_reply":"2025-06-23T13:42:36.475054Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained(\n    model_checkpoint,\n    id2label=id2label,\n    label2id=label2id,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T13:42:42.883020Z","iopub.execute_input":"2025-06-23T13:42:42.883287Z","iopub.status.idle":"2025-06-23T13:42:43.118966Z","shell.execute_reply.started":"2025-06-23T13:42:42.883268Z","shell.execute_reply":"2025-06-23T13:42:43.118249Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"from torch.optim import AdamW\n\noptimizer = AdamW(model.parameters(), lr=2e-5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T13:42:49.597589Z","iopub.execute_input":"2025-06-23T13:42:49.598073Z","iopub.status.idle":"2025-06-23T13:42:49.602249Z","shell.execute_reply.started":"2025-06-23T13:42:49.598050Z","shell.execute_reply":"2025-06-23T13:42:49.601468Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"from accelerate import Accelerator\n\naccelerator = Accelerator()\nmodel, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n    model, optimizer, train_dataloader, eval_dataloader\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T13:42:57.063479Z","iopub.execute_input":"2025-06-23T13:42:57.063776Z","iopub.status.idle":"2025-06-23T13:42:57.260305Z","shell.execute_reply.started":"2025-06-23T13:42:57.063755Z","shell.execute_reply":"2025-06-23T13:42:57.259578Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"from transformers import get_scheduler\n\nnum_train_epochs = 3\nnum_update_steps_per_epoch = len(train_dataloader)\nnum_training_steps = num_train_epochs * num_update_steps_per_epoch\n\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T13:43:04.490689Z","iopub.execute_input":"2025-06-23T13:43:04.491242Z","iopub.status.idle":"2025-06-23T13:43:04.495081Z","shell.execute_reply.started":"2025-06-23T13:43:04.491220Z","shell.execute_reply":"2025-06-23T13:43:04.494425Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"model_name = \"bert-finetuned-ner-accelerate\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T13:43:46.552506Z","iopub.execute_input":"2025-06-23T13:43:46.553067Z","iopub.status.idle":"2025-06-23T13:43:46.555908Z","shell.execute_reply.started":"2025-06-23T13:43:46.553046Z","shell.execute_reply":"2025-06-23T13:43:46.555275Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"def postprocess(predictions, labels):\n    predictions = predictions.detach().cpu().clone().numpy()\n    labels = labels.detach().cpu().clone().numpy()\n\n    # Remove ignored index (special tokens) and convert to labels\n    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n    true_predictions = [\n        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    return true_labels, true_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T13:44:01.977249Z","iopub.execute_input":"2025-06-23T13:44:01.977919Z","iopub.status.idle":"2025-06-23T13:44:01.982740Z","shell.execute_reply.started":"2025-06-23T13:44:01.977891Z","shell.execute_reply":"2025-06-23T13:44:01.981946Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"from tqdm.auto import tqdm\nimport torch\n\nprogress_bar = tqdm(range(num_training_steps))\n\nfor epoch in range(num_train_epochs):\n    # Training\n    model.train()\n    for batch in train_dataloader:\n        outputs = model(**batch)\n        loss = outputs.loss\n        accelerator.backward(loss)\n\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n        progress_bar.update(1)\n\n    # Evaluation\n    model.eval()\n    for batch in eval_dataloader:\n        with torch.no_grad():\n            outputs = model(**batch)\n\n        predictions = outputs.logits.argmax(dim=-1)\n        labels = batch[\"labels\"]\n\n        # Necessary to pad predictions and labels for being gathered\n        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n\n        predictions_gathered = accelerator.gather(predictions)\n        labels_gathered = accelerator.gather(labels)\n\n        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n        metric.add_batch(predictions=true_predictions, references=true_labels)\n\n    results = metric.compute()\n    print(\n        f\"epoch {epoch}:\",\n        {\n            key: results[f\"overall_{key}\"]\n            for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]\n        },\n    )\n\n    # Save and upload\n    accelerator.wait_for_everyone()\n    unwrapped_model = accelerator.unwrap_model(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T13:49:15.933287Z","iopub.execute_input":"2025-06-23T13:49:15.933804Z","iopub.status.idle":"2025-06-23T13:58:03.297390Z","shell.execute_reply.started":"2025-06-23T13:49:15.933775Z","shell.execute_reply":"2025-06-23T13:58:03.296770Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5268 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34aecc96de464904984a1bddf0b6b8c2"}},"metadata":{}},{"name":"stdout","text":"epoch 0: {'precision': 0.9397509256142713, 'recall': 0.920085681331356, 'f1': 0.9298143368578803, 'accuracy': 0.9846941779007476}\nepoch 1: {'precision': 0.9461460787613598, 'recall': 0.9281822684497276, 'f1': 0.9370780898408201, 'accuracy': 0.9855624889621475}\nepoch 2: {'precision': 0.9461460787613598, 'recall': 0.9281822684497276, 'f1': 0.9370780898408201, 'accuracy': 0.9855624889621475}\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}